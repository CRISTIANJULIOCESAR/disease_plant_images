{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yTswyRU0kFRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "!pip install torch==1.9.1\n",
        "!pip install torchvision==0.10.1"
      ],
      "metadata": {
        "id": "INMyUoFmkDyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "# Ruta del archivo ZIP que deseas descomprimir en Google Drive\n",
        "ruta_zip = '/content/drive/MyDrive/HOJAS/Hojas-20240131T050046Z-001.zip'  # Cambia esta ruta por la de tu archivo ZIP\n",
        "\n",
        "# Ruta de la carpeta donde deseas extraer los archivos\n",
        "ruta_destino = '/content/descomprimido/'  # Cambia esta ruta según tus preferencias\n",
        "\n",
        "# Descomprimir el archivo ZIP\n",
        "with zipfile.ZipFile(ruta_zip, 'r') as archivo_zip:\n",
        "    archivo_zip.extractall(ruta_destino)"
      ],
      "metadata": {
        "id": "taEbZDLDkBIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63BhFvFwkAbT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import inception_v3, Inception_V3_Weights\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configuración del dispositivo para usar CUDA si está disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Definición de transformaciones para las imágenes\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Función para cargar datos\n",
        "def load_data(train_directory, test_directory):\n",
        "    datasets = {\n",
        "        \"train\": ImageFolder(root=train_directory, transform=transform),\n",
        "        \"test\": ImageFolder(root=test_directory, transform=transform)\n",
        "    }\n",
        "    dataloaders = {\n",
        "        x: DataLoader(datasets[x], batch_size=32, shuffle=True) for x in ['train', 'test']\n",
        "    }\n",
        "    return dataloaders\n",
        "\n",
        "# Cargar y preparar el modelo InceptionV3\n",
        "def prepare_model(num_classes):\n",
        "    weights = Inception_V3_Weights.IMAGENET1K_V1\n",
        "    model = inception_v3(weights=weights, aux_logits=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "# Entrenamiento del modelo\n",
        "# Entrenamiento del modelo\n",
        "def train_and_evaluate_model(model, dataloaders, epochs=5):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Listas para guardar los valores de pérdida y precisión\n",
        "    train_losses, test_losses = [], []\n",
        "    train_accuracies, test_accuracies = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = total = 0\n",
        "\n",
        "        for inputs, labels in dataloaders['train']:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            if isinstance(outputs, tuple):  # Si hay salidas auxiliares, usa solo la principal\n",
        "                outputs = outputs[0]\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_losses.append(running_loss / len(dataloaders['train']))\n",
        "        train_accuracies.append(100 * correct / total)\n",
        "\n",
        "        # Evaluación\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dataloaders['test']:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                if isinstance(outputs, tuple):  # Si hay salidas auxiliares, usa solo la principal\n",
        "                    outputs = outputs[0]\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_losses.append(test_loss / len(dataloaders['test']))\n",
        "        test_accuracies.append(100 * correct / total)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}, '\n",
        "              f'Train Accuracy: {train_accuracies[-1]:.2f}%, Test Accuracy: {test_accuracies[-1]:.2f}%')\n",
        "\n",
        "    return train_losses, test_losses, train_accuracies, test_accuracies\n",
        "\n",
        "    # Gráfica de pérdidas\n",
        "# Directorios de entrenamiento y validación (actualiza estas rutas según tu configuración)\n",
        "# Directorios de entrenamiento y validación\n",
        "train_directory = '/content/descomprimido/Hojas/Train'\n",
        "test_directory = '/content/descomprimido/Hojas/Test'\n",
        "\n",
        "\n",
        "# Cargar datos de entrenamiento y validación\n",
        "dataloaders = load_data(train_directory, test_directory)\n",
        "\n",
        "# Definir el número de clases\n",
        "num_classes = 3  # Ajusta esto según tu conjunto de datos específico\n",
        "\n",
        "# Preparar y entrenar el modelo\n",
        "model = prepare_model(num_classes)\n",
        "#train_and_evaluate_model(model, dataloaders, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ejecutar entrenamiento y evaluación\n",
        "train_losses, test_losses, train_accuracies, test_accuracies = train_and_evaluate_model(model, dataloaders, epochs=20)\n",
        "\n",
        "# Graficar pérdidas\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(test_losses, label='Validation Loss')\n",
        "plt.title('Loss vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "# Graficar precisión\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(test_accuracies, label='Validation Accuracy')\n",
        "plt.title('Accuracy vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KqvHRqWblmBI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}